#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
qwen-agentæ™ºèƒ½ä½“ä½¿ç”¨ç¤ºä¾‹
"""

import json
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.ai_summary import HTMLContentExtractorAgent

def example_basic_extraction():
    """ç¤ºä¾‹ï¼šåŸºæœ¬å†…å®¹æå–"""
    print("=== åŸºæœ¬å†…å®¹æå–ç¤ºä¾‹ ===")
    
    # æµ‹è¯•HTMLå†…å®¹
    test_html = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>WebExtracto - æ™ºèƒ½ç½‘ç«™å†…å®¹æå–å·¥å…·</title>
    </head>
    <body>
        <header>
            <nav>
                <a href="/">é¦–é¡µ</a>
                <a href="/features">åŠŸèƒ½ç‰¹æ€§</a>
            </nav>
        </header>
        
        <main>
            <article>
                <h1>WebExtracto - æ™ºèƒ½ç½‘ç«™å†…å®¹æå–å·¥å…·</h1>
                <p>WebExtractoæ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç½‘ç«™å†…å®¹æå–å’Œåˆ†æå·¥å…·ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ä»ç½‘é¡µä¸­æå–æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚</p>
                
                <h2>ä¸»è¦åŠŸèƒ½</h2>
                <ul>
                    <li>æ™ºèƒ½å†…å®¹æå–ï¼šè‡ªåŠ¨è¯†åˆ«å’Œæå–ç½‘é¡µä¸­çš„ä¸»è¦å†…å®¹</li>
                    <li>AIæ€»ç»“åˆ†æï¼šä½¿ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯å¯¹å†…å®¹è¿›è¡Œæ€»ç»“å’Œåˆ†æ</li>
                    <li>ç»“æ„åŒ–è¾“å‡ºï¼šå°†æå–çš„å†…å®¹è½¬æ¢ä¸ºç»“æ„åŒ–çš„æ•°æ®æ ¼å¼</li>
                    <li>æ‰¹é‡å¤„ç†ï¼šæ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªç½‘é¡µ</li>
                </ul>
                
                <h2>æŠ€æœ¯ç‰¹ç‚¹</h2>
                <p>WebExtractoé‡‡ç”¨å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«æ–‡ç« å†…å®¹ã€äº§å“ä¿¡æ¯ã€å…¬å¸ä»‹ç»ç­‰å¤šç§ç±»å‹çš„å†…å®¹ã€‚</p>
            </article>
        </main>
        
        <footer>
            <p>ç‰ˆæƒæ‰€æœ‰ Â© 2024 WebExtracto</p>
        </footer>
    </body>
    </html>
    """
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = HTMLContentExtractorAgent()
    
    # æå–å†…å®¹
    result = agent.extract_content(test_html, "https://webextracto.com")
    
    print("æå–ç»“æœ:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

def example_agent_analysis():
    """ç¤ºä¾‹ï¼šæ™ºèƒ½ä½“åˆ†æ"""
    print("\n=== æ™ºèƒ½ä½“åˆ†æç¤ºä¾‹ ===")
    
    # æµ‹è¯•HTMLå†…å®¹
    test_html = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>Pythonç¼–ç¨‹æŠ€å·§å¤§å…¨</title>
    </head>
    <body>
        <article>
            <h1>Pythonç¼–ç¨‹æŠ€å·§å¤§å…¨</h1>
            <p>Pythonæ˜¯ä¸€ç§å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œå…·æœ‰ç®€æ´çš„è¯­æ³•å’Œä¸°å¯Œçš„åº“ã€‚</p>
            <p>æœ¬æ–‡ä»‹ç»äº†ä¸€äº›å®ç”¨çš„Pythonç¼–ç¨‹æŠ€å·§ï¼ŒåŒ…æ‹¬åˆ—è¡¨æ¨å¯¼å¼ã€è£…é¥°å™¨ã€ç”Ÿæˆå™¨ç­‰é«˜çº§ç‰¹æ€§ã€‚</p>
            
            <h2>åˆ—è¡¨æ¨å¯¼å¼</h2>
            <p>åˆ—è¡¨æ¨å¯¼å¼æ˜¯Pythonä¸­éå¸¸å®ç”¨çš„ç‰¹æ€§ï¼Œå¯ä»¥ç®€æ´åœ°åˆ›å»ºåˆ—è¡¨ã€‚</p>
            
            <h2>è£…é¥°å™¨</h2>
            <p>è£…é¥°å™¨æ˜¯Pythonä¸­çš„é«˜çº§ç‰¹æ€§ï¼Œå¯ä»¥ä¼˜é›…åœ°ä¿®æ”¹å‡½æ•°çš„è¡Œä¸ºã€‚</p>
        </article>
    </body>
    </html>
    """
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = HTMLContentExtractorAgent()
    
    # ä½¿ç”¨æ™ºèƒ½ä½“åˆ†æ
    analysis = agent.analyze_with_agent(
        test_html, 
        "https://example.com/python-tips",
        "è¯·åˆ†æè¿™ç¯‡æ–‡ç« çš„ä¸»è¦å†…å®¹å’ŒæŠ€æœ¯è¦ç‚¹"
    )
    
    print("æ™ºèƒ½ä½“åˆ†æç»“æœ:")
    print(analysis)

def example_batch_processing():
    """ç¤ºä¾‹ï¼šæ‰¹é‡å¤„ç†"""
    print("\n=== æ‰¹é‡å¤„ç†ç¤ºä¾‹ ===")
    
    # å¤šä¸ªHTMLå†…å®¹
    html_contents = [
        {
            "html_content": """
            <html><head><title>äººå·¥æ™ºèƒ½å…¥é—¨</title></head>
            <body><article><h1>äººå·¥æ™ºèƒ½å…¥é—¨</h1>
            <p>äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚</p>
            <p>æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ ã€‚</p>
            </article></body></html>
            """,
            "url": "https://example.com/ai-intro"
        },
        {
            "html_content": """
            <html><head><title>æ·±åº¦å­¦ä¹ åŸºç¡€</title></head>
            <body><article><h1>æ·±åº¦å­¦ä¹ åŸºç¡€</h1>
            <p>æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„ç‰¹å¾ã€‚</p>
            <p>æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚</p>
            </article></body></html>
            """,
            "url": "https://example.com/deep-learning"
        }
    ]
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = HTMLContentExtractorAgent()
    
    # æ‰¹é‡å¤„ç†
    results = agent.batch_extract(html_contents)
    
    print("æ‰¹é‡å¤„ç†ç»“æœ:")
    for i, result in enumerate(results):
        print(f"\n--- ç¬¬ {i+1} ä¸ªç»“æœ ---")
        print(json.dumps(result, ensure_ascii=False, indent=2))

def example_quality_assessment():
    """ç¤ºä¾‹ï¼šå†…å®¹è´¨é‡è¯„ä¼°"""
    print("\n=== å†…å®¹è´¨é‡è¯„ä¼°ç¤ºä¾‹ ===")
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„HTMLå†…å®¹
    test_contents = [
        {
            "name": "é«˜è´¨é‡æ–‡ç« ",
            "content": """
            <html><head><title>æœºå™¨å­¦ä¹ ç®—æ³•è¯¦è§£</title></head>
            <body><article><h1>æœºå™¨å­¦ä¹ ç®—æ³•è¯¦è§£</h1>
            <p>æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ ã€‚</p>
            <p>æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ç­‰ä¸»è¦ç®—æ³•ç±»å‹ã€‚</p>
            <p>æ¯ç§ç®—æ³•éƒ½æœ‰å…¶é€‚ç”¨åœºæ™¯å’Œä¼˜ç¼ºç‚¹ï¼Œé€‰æ‹©åˆé€‚çš„ç®—æ³•å¯¹æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚</p>
            </article></body></html>
            """
        },
        {
            "name": "å¹¿å‘Šé¡µé¢",
            "content": """
            <html><head><title>é™æ—¶ä¼˜æƒ </title></head>
            <body><div class="ad">
            <h1>é™æ—¶ä¼˜æƒ æ´»åŠ¨</h1><p>ç«‹å³è´­ä¹°ï¼Œäº«å—8æŠ˜ä¼˜æƒ ï¼</p>
            <button>ç‚¹å‡»è´­ä¹°</button><p>å¹¿å‘Šæ¨å¹¿å†…å®¹</p></div></body></html>
            """
        },
        {
            "name": "å¯¼èˆªé¡µé¢",
            "content": """
            <html><head><title>ç½‘ç«™å¯¼èˆª</title></head>
            <body><nav>
            <ul><li><a href="/">é¦–é¡µ</a></li><li><a href="/about">å…³äºæˆ‘ä»¬</a></li>
            <li><a href="/contact">è”ç³»æˆ‘ä»¬</a></li></ul></nav>
            <div><p>è¿™æ˜¯ä¸€ä¸ªå¯¼èˆªé¡µé¢</p></div></body></html>
            """
        }
    ]
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = HTMLContentExtractorAgent()
    
    for test in test_contents:
        print(f"\n--- è¯„ä¼°: {test['name']} ---")
        
        # è·å–è´¨é‡è¯„åˆ†
        quality = agent.get_content_quality_score(test['content'])
        
        print("è´¨é‡è¯„åˆ†:")
        print(json.dumps(quality, ensure_ascii=False, indent=2))
        
        # æå–å†…å®¹
        result = agent.extract_content(test['content'], f"https://example.com/{test['name']}")
        
        if result['success']:
            print("âœ… å†…å®¹æœ‰æ•ˆ")
        else:
            print(f"âŒ å†…å®¹æ— æ•ˆ: {result.get('message', '')}")

def example_tool_function():
    """ç¤ºä¾‹ï¼šå·¥å…·å‡½æ•°ä½¿ç”¨"""
    print("\n=== å·¥å…·å‡½æ•°ä½¿ç”¨ç¤ºä¾‹ ===")
    
    from core.ai_summary import html_content_extractor
    
    # æµ‹è¯•HTMLå†…å®¹
    test_html = """
    <html><head><title>æ•°æ®ç§‘å­¦å…¥é—¨</title></head>
    <body><article><h1>æ•°æ®ç§‘å­¦å…¥é—¨</h1>
    <p>æ•°æ®ç§‘å­¦æ˜¯ä¸€ä¸ªè·¨å­¦ç§‘é¢†åŸŸï¼Œç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸçŸ¥è¯†ã€‚</p>
    <p>æ•°æ®ç§‘å­¦å®¶éœ€è¦æŒæ¡æ•°æ®æ¸…æ´—ã€æ¢ç´¢æ€§æ•°æ®åˆ†æã€æœºå™¨å­¦ä¹ ç­‰æŠ€èƒ½ã€‚</p>
    </article></body></html>
    """
    
    # ä½¿ç”¨å·¥å…·å‡½æ•°
    result = html_content_extractor(test_html, "https://example.com/data-science")
    
    print("å·¥å…·å‡½æ•°ç»“æœ:")
    print(result)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ qwen-agentæ™ºèƒ½ä½“ä½¿ç”¨ç¤ºä¾‹")
    
    try:
        # è¿è¡Œç¤ºä¾‹
        example_basic_extraction()
        example_agent_analysis()
        example_batch_processing()
        example_quality_assessment()
        example_tool_function()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        print("è¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®qwen-agentç¯å¢ƒ")

if __name__ == "__main__":
    main() 